{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "214f40ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdb5e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "from faster_whisper import WhisperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9219c8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    patterns = {\n",
    "        'medicines': r'\\b[A-Za-z]{3,}(?:mycin|cillin|oxacin|azole|prazole|dipine|olol|sartan|statin|pril)\\b',\n",
    "        'dosages': r'\\b\\d+\\s*(?:mg|ml|mcg|g|kg|cc|iu|units?)\\b',\n",
    "        'frequencies': r'\\b(?:once|twice|thrice|daily|BD|TDS|QDS|OD|HS|PRN|SOS)\\b',\n",
    "        'duration': r'\\b\\d+\\s*(?:days?|weeks?|months?|hours?)\\b',\n",
    "        'numbers': r'\\b\\d+(?:\\.\\d+)?\\b',\n",
    "        'english_words': r'\\b[A-Za-z]{2,}\\b'\n",
    "    }\n",
    "    result = {k: list(set(re.findall(v, text, re.I))) for k, v in patterns.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83a64a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0e6939d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Whisper model (large-v3)...\n",
      "Model loaded in 8.12 sec\n",
      "\n",
      "Transcribing English pass...\n",
      "English Pass Time  : 16.65 sec\n",
      "Transcribing Marathi/Hindi pass...\n",
      "Marathi transcription done in 36.14 sec\n",
      "\n",
      "Entity extraction completed in 0.00 sec\n",
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY\n",
      "================================================================================\n",
      "Model Load Time    : 8.12 sec\n",
      "English Pass Time  : 16.65 sec\n",
      "Marathi Pass Time  : 36.14 sec\n",
      "Entity Extraction  : 0.00 sec\n",
      "TOTAL PIPELINE LATENCY : 60.91 sec\n",
      "================================================================================\n",
      "\n",
      "ENGLISH TRANSCRIPT:\n",
      " Let's see what I am going to do. I am going to use a new model. And I am going to see what features are there in this model. So, let's see what is there. \n",
      "\n",
      "MARATHI TRANSCRIPT:\n",
      " बगाता में काई करतो, मी नवीन मॉडल यूज़ करालोई अनी हे मॉडल मधे काई काई फीचर्स हाई ते पन बगायरोई मी, सो बगीवा काई हाई अता \n",
      "\n",
      "EXTRACTED ENTITIES:\n",
      "English_words: to, So, And, model, features, is, there, what, going, use...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_dir = \"./models/large-v3\" \n",
    "start_total = time.time()\n",
    "print(\"Loading Whisper model (large-v3)...\")\n",
    "load_start = time.time()\n",
    "whisper = WhisperModel(model_dir, device=\"cpu\", compute_type=\"int8\")\n",
    "load_time = time.time() - load_start\n",
    "print(f\"Model loaded in {load_time:.2f} sec\\n\")\n",
    "\n",
    "#===========================================================================\n",
    "audio_path = r\"E:\\Projects\\Med_Scribe\\Testing\\output_audio.wav\"\n",
    "\n",
    "#===========================================================================\n",
    "print(\"Transcribing English pass...\")\n",
    "start_en = time.time()\n",
    "segments_en , info_en = whisper.transcribe(audio_path, language='en', beam_size=15, vad_filter=True)\n",
    "en_text = \" \".join([seg.text.strip() for seg in segments_en])\n",
    "lat_en = time.time() - start_en\n",
    "print(f\"English Pass Time  : {lat_en:.2f} sec\")\n",
    "#===========================================================================\n",
    "print(\"Transcribing Marathi/Hindi pass...\")\n",
    "start_mr = time.time()\n",
    "segments_mr , info_mr = whisper.transcribe(audio_path, language='mr', beam_size=15, vad_filter=True)\n",
    "mr_text = \" \".join([seg.text.strip() for seg in segments_mr])\n",
    "lat_mr = time.time() - start_mr\n",
    "print(f\"Marathi transcription done in {lat_mr:.2f} sec\\n\")\n",
    "\n",
    "#============================================================================\n",
    "start_ent = time.time()\n",
    "entities = extract_entities(en_text)\n",
    "lat_ent = time.time() - start_ent\n",
    "print(f\"Entity extraction completed in {lat_ent:.2f} sec\\n\")\n",
    "\n",
    "total_time = time.time() - start_total\n",
    "print(\"=\"*80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Model Load Time    : {load_time:.2f} sec\")\n",
    "print(f\"English Pass Time  : {lat_en:.2f} sec\")\n",
    "print(f\"Marathi Pass Time  : {lat_mr:.2f} sec\")\n",
    "print(f\"Entity Extraction  : {lat_ent:.2f} sec\")\n",
    "print(f\"TOTAL PIPELINE LATENCY : {total_time:.2f} sec\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nENGLISH TRANSCRIPT:\\n\", en_text.strip()[:500], \"...\" if len(en_text) > 500 else \"\")\n",
    "print(\"\\nMARATHI TRANSCRIPT:\\n\", mr_text.strip()[:500], \"...\" if len(mr_text) > 500 else \"\")\n",
    "print(\"\\nEXTRACTED ENTITIES:\")\n",
    "for k, v in entities.items():\n",
    "    if v:\n",
    "        print(f\"{k.capitalize()}: {', '.join(v[:10])}{'...' if len(v)>10 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99252217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 197.92 MB\n",
      "GPU used: 3839.26 MB\n",
      "GPU reserved: 3930.00 MB\n",
      "JSON found but invalid\n",
      "{\n",
      "  \"error\": \"Invalid JSON output\",\n",
      "  \"raw_output\": \"\\nYou are a medical prescription parser. Extract ONLY information explicitly stated.\\n\\nRules:\\n1. Extract medicines with EXACT dosages mentioned\\n2. If dosage/frequency unclear, mark as \\\"unspecified\\\"\\n3. Do NOT infer or assume any information\\n4. If doctor says \\\"continue previous meds\\\", extract NOTHING\\n5. Output valid JSON only\\n\\nOutput format:\\n{\\n\\\"medicines\\\": [{\\\"name\\\": str, \\\"dosage\\\": str, \\\"frequency\\\": str, \\\"duration\\\": str}],\\n\\\"diseases\\\": [str],\\n\\\"tests\\\": [{\\\"name\\\": str, \\\"timing\\\": str}]\\n}\\n\\nExtract from this prescription conversation:\\n Mr. Patil, after reading your reports, I can see that you do have some fatty liver and sugar levels, but don't worry. It's the early stage. Take Metformin 500mg in the morning and evening and take 1 tablet after breakfast. Take 2 tsp of Live 1252 Syrup twice a day. Stop eating oily and sugary foods. Walk for 30 minutes daily. One more thing, do an ultrasound of abdomen for the next visit. I want to see your liver condition. Take medicine continuously for 30 days and follow it. And yes, take food on time. Don't eat late at night. Otherwise, you won't be able to control your sugar levels. Let's take a look. \\n\\nRemember: Only extract explicitly stated information. No assumptions.\\n```json\\n{\\n\\\"medicines\\\": [\\n    {\\n        \\\"name\\\": \\\"Metformin\\\",\\n        \\\"dosage\\\": \\\"500mg\\\",\\n        \\\"frequency\\\": \\\"morning and evening\\\",\\n        \\\"duration\\\": \\\"30 days\\\"\\n    },\\n    {\\n        \\\"name\\\": \\\"Live 1252 Syrup\\\",\\n        \\\"dosage\\\": \\\"2 tsp\\\",\\n        \\\"frequency\\\": \\\"twice a day\\\"\\n    }\\n],\\n\\\"diseases\\\": [\\n    \\\"fatty liver\\\",\\n    \\\"sugar levels\\\"\\n],\\n\\\"tests\\\": [\\n    \\\"ultasonogram of abdomen\\\"\\n]\\n}\\n```\\n\"\n",
      "}\n",
      "RAM used: 821.76 MB\n",
      "GPU used: 3847.40 MB\n",
      "GPU reserved: 4006.00 MB\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import json\n",
    "\n",
    "model_dir = \"./models/gemma-3-1b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "transcript = \" Mr. Patil, after reading your reports, I can see that you do have some fatty liver and sugar levels, but don't worry. It's the early stage. Take Metformin 500mg in the morning and evening and take 1 tablet after breakfast. Take 2 tsp of Live 1252 Syrup twice a day. Stop eating oily and sugary foods. Walk for 30 minutes daily. One more thing, do an ultrasound of abdomen for the next visit. I want to see your liver condition. Take medicine continuously for 30 days and follow it. And yes, take food on time. Don't eat late at night. Otherwise, you won't be able to control your sugar levels. Let's take a look. \"\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "You are a medical prescription parser. Extract ONLY information explicitly stated.\n",
    "\n",
    "Rules:\n",
    "1. Extract medicines with EXACT dosages mentioned\n",
    "2. If dosage/frequency unclear, mark as \"unspecified\"\n",
    "3. Do NOT infer or assume any information\n",
    "4. If doctor says \"continue previous meds\", extract NOTHING\n",
    "5. Output valid JSON only\n",
    "\n",
    "Output format:\n",
    "{{\n",
    "\"medicines\": [{{\"name\": str, \"dosage\": str, \"frequency\": str, \"duration\": str}}],\n",
    "\"diseases\": [str],\n",
    "\"tests\": [{{\"name\": str, \"timing\": str}}]\n",
    "}}\n",
    "\n",
    "Extract from this prescription conversation:\n",
    "{transcript}\n",
    "\n",
    "Remember: Only extract explicitly stated information. No assumptions.\n",
    "\"\"\"\n",
    "import psutil\n",
    "print(f\"RAM used: {psutil.Process().memory_info().rss / 1024**2:.2f} MB\")\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU used: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
    "    print(f\"GPU reserved: {torch.cuda.memory_reserved()/1024**2:.2f} MB\")\n",
    "\n",
    "inputs = tokenizer(user_prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=512)\n",
    "result_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "try:\n",
    "    results_json = json.loads(result_text)\n",
    "except:\n",
    "    result_json = {\"error\": \"Invalid JSON output\", \"raw_output\": result_text}\n",
    "\n",
    "import json\n",
    "\n",
    "raw = result_json['raw_output']  # your previous output\n",
    "\n",
    "# Find first { and last } and extract\n",
    "start = raw.find(\"{\")\n",
    "end = raw.rfind(\"}\") + 1\n",
    "\n",
    "if start != -1 and end != -1:\n",
    "    json_str = raw[start:end]\n",
    "    try:\n",
    "        clean_json = json.loads(json_str)\n",
    "        print(json.dumps(clean_json, indent=2))\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"JSON found but invalid\")\n",
    "else:\n",
    "    print(\"No JSON found\")\n",
    "\n",
    "print(json.dumps(result_json, indent=2))\n",
    "\n",
    "print(f\"RAM used: {psutil.Process().memory_info().rss / 1024**2:.2f} MB\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU used: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
    "    print(f\"GPU reserved: {torch.cuda.memory_reserved()/1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32c61ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medscribe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
